# ğŸ¤– AutoML Fraud Detection System - AÃ¯obi

> SystÃ¨me automatisÃ© de dÃ©tection de fraude utilisant un Meta-Transformer ML pour prÃ©dire les hyperparamÃ¨tres optimaux

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![XGBoost](https://img.shields.io/badge/XGBoost-1.7+-green.svg)](https://xgboost.readthedocs.io/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![Railway](https://img.shields.io/badge/Deploy-Railway-blueviolet.svg)](https://railway.app/)

## ğŸ“š Documentation

- **[ğŸš€ Guide DÃ©ploiement Rapide](DEPLOIEMENT_RAPIDE.md)** - DÃ©ployer sur Railway en 10 minutes
- **[ğŸ“‹ Configuration Variables](APP_autoML/docs/VARIABLES_ENVIRONNEMENT.md)** - Guide complet des variables d'environnement
- **[ğŸ”§ Documentation Technique](APP_autoML/RAILWAY_DEPLOYMENT.md)** - Guide dÃ©taillÃ© de dÃ©ploiement

## ğŸš€ Quick Start

### Application Web (RecommandÃ©)

```bash
# 1. Installation
cd APP_autoML
pip install -r requirements.txt

# 2. Configuration
cp .env.example .env
# Ã‰diter .env avec vos credentials

# 3. Lancer l'application
python run.py
```

AccÃ©der Ã : http://127.0.0.1:5000

**FonctionnalitÃ©s**:
- âœ… Interface web intuitive
- âœ… Upload de datasets
- âœ… Training automatique avec AutoML
- âœ… PrÃ©dictions en temps rÃ©el
- âœ… Dashboard d'historique
- âœ… Panneau d'administration
- âœ… Login Google OAuth
- âœ… Stockage S3 des modÃ¨les

### Ligne de Commande (Advanced)

```bash
# 1. Placer votre dataset
cp votre_fichier.csv data/datasets/MonDataset.csv

# 2. Lancer l'AutoML (auto-dÃ©tecte tout)
python automl_transformer/full_automl.py data/datasets/MonDataset.csv

# 3. VÃ©rifier les rÃ©sultats
python show_automl_results.py
```

**C'est tout!** Le systÃ¨me a:
- âœ… DÃ©tectÃ© automatiquement les colonnes (amount, time, categorical)
- âœ… GÃ©nÃ©rÃ© 7-28 features automatiquement
- âœ… PrÃ©dit les meilleurs hyperparamÃ¨tres via Meta-Transformer ML
- âœ… EntraÃ®nÃ© et Ã©valuÃ© le modÃ¨le XGBoost
- âœ… SauvegardÃ© le pipeline complet pour production

## ğŸ“Š RÃ©sultats

### Performance vs Grid Search

| Dataset | Grid Search F1 | AutoML F1 | Temps Grid | Temps AutoML | Speedup |
|---------|---------------|-----------|------------|--------------|---------|
| Dataset4 | 0.8133 | 0.7886 | 400s+ | 4s | **100x** |
| Dataset5 | 0.6055 | 0.5693 | 400s+ | 4s | **100x** |
| Dataset6 | 0.8858 | **1.0000** ğŸ† | 400s+ | 4s | **100x** |
| Dataset7 | 0.7283 | **1.0000** ğŸ† | 400s+ | 4s | **100x** |

**Highlights:**
- ğŸ† **2/5 datasets**: AutoML MEILLEUR que Grid Search (F1 = 1.0!)
- âš¡ **100x plus rapide** (4s vs 400s+)
- ğŸ¯ **Aucune configuration** requise
- ğŸ“¦ **Pipeline complet** sauvegardÃ© automatiquement

### âš ï¸ DÃ©couverte Importante: Data Leakage dans Dataset6 & Dataset7

**Investigation des scores parfaits (F1=1.0):**

AprÃ¨s investigation approfondie, nous avons dÃ©couvert que les scores parfaits sur Dataset6 et Dataset7 sont dus Ã  du **data leakage** (fuite d'information):

**Dataset6 - LEAKAGE SÃ‰VÃˆRE ğŸš¨:**
- Tests avec features brutes (sans engineering):
  - Random Forest: **F1=0.93** ğŸš¨
  - XGBoost: **F1=0.90** ğŸš¨ (mÃªme algo que l'AutoML)
- PrÃ©dicteurs parfaits identifiÃ©s:
  - `type_transaction="paiement"` â†’ **0% fraud** (1414 cas = 13%)
  - `destination_country="GH/NG"` â†’ **100% fraud** (60 cas)
  - `montant_transaction`: corrÃ©lation **+0.41** (fraudes 8x plus Ã©levÃ©es)
- **Verdict**: Dataset contaminÃ©, inutilisable en production rÃ©elle

**Dataset7 - LEAKAGE MODÃ‰RÃ‰ âš ï¸:**
- Tests avec features brutes (sans engineering):
  - Random Forest: **F1=0.65** âš ï¸
  - XGBoost: **F1â‰ˆ0.65** âš ï¸ (mÃªme algo que l'AutoML)
- PrÃ©dicteurs parfaits: `transaction_type="payment"` â†’ 0% fraud (2115 cas)
- **Gain du feature engineering**: +0.35 (Ã©norme!)
- **Verdict**: Le F1=1.0 vient surtout de l'intelligence du feature engineering

**Note**: Random Forest est utilisÃ© uniquement pour tests rapides. L'AutoML utilise **XGBoost** partout.

**Conclusion:**
- âœ… L'AutoML **fonctionne correctement** - il trouve les patterns (mÃªme artificiels)
- âœ… Pour validation rÃ©elle, utiliser **Dataset4, 5, 9** (F1=0.57-0.79, rÃ©aliste)
- ğŸ“š Documentation complÃ¨te: [`docs/DATA_LEAKAGE_ANALYSIS.md`](docs/DATA_LEAKAGE_ANALYSIS.md)
- ğŸ”¬ Script d'analyse: [`tests/check_dataset6_leakage.py`](tests/check_dataset6_leakage.py)

## ğŸ¯ FonctionnalitÃ©s

### ï¿½ Architecture: Deux Meta-Transformers

**âš ï¸ Le projet utilise actuellement l'ANCIEN Meta-Transformer** (plus fiable):

| Composant | Ancien (âœ… UtilisÃ©) | Nouveau (ğŸ§ª ExpÃ©rimental) |
|-----------|-------------------|------------------------|
| **Fichier** | `ancien_meta/train_metatransformer.py` | `automl_transformer/train_automl_metatransformer.py` |
| **Type** | Transformer PyTorch (4 layers, 128 hidden) | Transformer avec approche diffÃ©rente |
| **EntraÃ®nement** | 7 datasets, 105 exemples | Approche plus automatisÃ©e |
| **Performance** | RÂ² max_depth=0.83, stable | En dÃ©veloppement |
| **Usage** | ChargÃ© dans `full_automl.py` ligne 195-270 | Non utilisÃ© par dÃ©faut |
| **Fallback** | Hyperparams par dÃ©faut si NaN | - |

**Pourquoi deux versions?**
- L'ancien modÃ¨le a fait ses preuves (Dataset6/7: F1=1.0)
- Le nouveau Ã©tait expÃ©rimental avec performances initiales insuffisantes
- L'ancien est intÃ©grÃ© directement pour garantir la fiabilitÃ©
- Fallback robuste: si prÃ©diction Ã©choue â†’ hyperparams par dÃ©faut fonctionnent bien

### ï¿½ğŸ¤– Auto Feature Engineering
- **DÃ©tection automatique** des types de colonnes
  - Amount/Money columns: transformations log, sqrt, bins, flags
  - Temporal columns: hour, day, weekend, business hours
  - Name columns: length, word count
  - Categorical: label encoding automatique

### ğŸ§  Meta-Transformer ML
- **PrÃ©diction d'hyperparamÃ¨tres** basÃ©e sur les caractÃ©ristiques du dataset
- EntraÃ®nÃ© sur 7 datasets de rÃ©fÃ©rence (105 exemples)
- PrÃ©dit 10 hyperparamÃ¨tres XGBoost en ~1 seconde

### âš¡ Pipeline Production-Ready
- Sauvegarde automatique: modÃ¨le + transformations
- Format joblib pour chargement rapide
- MÃ©triques complÃ¨tes: F1, AUC, Confusion Matrix
- Support multilingue: yes/no, oui/non, 1/0

## ğŸ“ Structure du Projet

```
fraud-project/
â”œâ”€â”€ automl_transformer/          # ğŸ¤– AutoML Principal
â”‚   â”œâ”€â”€ full_automl.py           # â† Point d'entrÃ©e principal
â”‚   â”œâ”€â”€ auto_feature_engineer.py # Feature engineering automatique
â”‚   â””â”€â”€ auto_feature_selector.py # SÃ©lection de features
â”‚
â”œâ”€â”€ ancien_meta/                 # ğŸ§  Meta-Transformer
â”‚   â”œâ”€â”€ train_metatransformer.py # EntraÃ®ner le Meta-Transformer
â”‚   â””â”€â”€ create_unified_metatransformer_dataset.py
â”‚
â”œâ”€â”€ base/                        # ğŸ“Š Baseline & PrÃ©paration
â”‚   â”œâ”€â”€ baseline_xgboost.py      # Grid Search manuel
â”‚   â””â”€â”€ create_metamodel_examples.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ datasets/                # ğŸ“ CSVs bruts
â”‚   â”œâ”€â”€ automl_models/           # ğŸ’¾ ModÃ¨les AutoML sauvegardÃ©s
â”‚   â””â”€â”€ models/                  # ğŸ§  Meta-Transformer (.pth)
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ GUIDE_UTILISATION_AUTOML.md  # ğŸ“˜ Guide complet
â”‚
â”œâ”€â”€ show_automl_results.py       # ğŸ“Š Afficher les rÃ©sultats
â””â”€â”€ compare_automl_vs_manual.py  # ğŸ“ˆ Comparer AutoML vs Grid Search
```

## ğŸ“š Documentation

- **[Guide d'Utilisation Complet](docs/GUIDE_UTILISATION_AUTOML.md)** - Comment utiliser l'AutoML
  - PrÃ©diction sur nouveau dataset
  - EntraÃ®ner avec nouveaux datasets
  - RÃ©entraÃ®ner le Meta-Transformer
  - Troubleshooting complet

- **[RÃ©sultats Finaux](AUTOML_FINAL_RESULTS.md)** - Performance dÃ©taillÃ©e

## ğŸ› ï¸ Installation

### PrÃ©requis
```bash
Python 3.8+
```

### Installation des DÃ©pendances
```bash
pip install -r requirements.txt
```

**DÃ©pendances principales:**
- `xgboost>=1.7.0` - ModÃ¨le de classification
- `torch>=2.0.0` - Meta-Transformer
- `scikit-learn>=1.0.0` - Preprocessing et mÃ©triques
- `pandas>=1.5.0` - Manipulation de donnÃ©es
- `numpy>=1.23.0` - Calculs numÃ©riques
- `imbalanced-learn>=0.10.0` - SMOTE pour dÃ©sÃ©quilibre
- `joblib>=1.2.0` - Sauvegarde des modÃ¨les

## ğŸ’¡ Exemples d'Usage

### Exemple 1: PrÃ©diction Simple
```python
from automl_transformer.full_automl import FullAutoML

# CrÃ©er l'AutoML
automl = FullAutoML(use_meta_transformer=True)

# EntraÃ®ner sur votre dataset
performance = automl.fit(
    csv_path='data/datasets/MonDataset.csv',
    target_col='fraud_flag'  # Optionnel (auto-dÃ©tectÃ©)
)

print(f"F1 Score: {performance['test_f1']:.4f}")
print(f"AUC: {performance['test_auc']:.4f}")
```

### Exemple 2: Utilisation en Production
```python
import joblib
import pandas as pd

# Charger le pipeline sauvegardÃ©
model = joblib.load('data/automl_models/mondataset/xgboost_model.joblib')
engineer = joblib.load('data/automl_models/mondataset/feature_engineer.joblib')

# Nouvelles transactions
new_data = pd.read_csv('nouvelles_transactions.csv')

# Feature engineering automatique
X_transformed = engineer.transform(new_data)

# PrÃ©dire
predictions = model.predict(X_transformed)
probabilities = model.predict_proba(X_transformed)[:, 1]

# RÃ©sultats
results = pd.DataFrame({
    'transaction_id': new_data['transaction_id'],
    'fraud_probability': probabilities,
    'is_fraud': predictions
})

# Filtrer les fraudes (seuil > 0.7)
fraudes_detectees = results[results['fraud_probability'] > 0.7]
```

### Exemple 3: Comparer avec Grid Search
```bash
# Lancer AutoML
python automl_transformer/full_automl.py data/datasets/Dataset4.csv

# Comparer avec Grid Search manuel
python compare_automl_vs_manual.py
```

## ğŸ”§ Configuration AvancÃ©e

### Modifier les HyperparamÃ¨tres par DÃ©faut

Si le Meta-Transformer prÃ©dit NaN, le systÃ¨me utilise des hyperparamÃ¨tres par dÃ©faut. Pour les modifier:

```python
# Dans automl_transformer/full_automl.py, ligne ~115

# Hyperparams par dÃ©faut
default_hyperparams = {
    'max_depth': 6,              # Profondeur des arbres (3-10)
    'learning_rate': 0.1,        # Taux d'apprentissage (0.01-0.3)
    'n_estimators': 300,         # Nombre d'arbres (100-500)
    'subsample': 0.8,            # Ã‰chantillonnage (0.6-1.0)
    'colsample_bytree': 0.8,     # Features par arbre (0.6-1.0)
    'gamma': 0.3,                # RÃ©gularisation (0-1)
    'min_child_weight': 5,       # Poids minimum (1-10)
    'scale_pos_weight': 'auto',  # Balance des classes (auto-calculÃ©)
    'reg_alpha': 0.1,            # L1 rÃ©gularisation
    'reg_lambda': 1.0            # L2 rÃ©gularisation
}
```

### Activer/DÃ©sactiver le Meta-Transformer

```python
# Utiliser Meta-Transformer ML (par dÃ©faut)
automl = FullAutoML(use_meta_transformer=True)

# Utiliser uniquement les hyperparams par dÃ©faut
automl = FullAutoML(use_meta_transformer=False)
```

## ğŸ§ª Tests

```bash
# Tester sur Dataset5
python automl_transformer/full_automl.py data/datasets/Dataset5.csv fraud_flag

# Tester sur Dataset6 (franÃ§ais)
python automl_transformer/full_automl.py data/datasets/Dataset6.csv label_suspect

# Tester sur Dataset7
python automl_transformer/full_automl.py data/datasets/Dataset7.csv suspicious_flag
```

## ğŸ“ˆ AmÃ©liorer les Performances

### ProblÃ¨me: Overfitting (Train F1 >> Test F1)

**Solution 1: RÃ©gularisation**
```python
# Augmenter la rÃ©gularisation
hyperparams = {
    'min_child_weight': 10,  # Au lieu de 5
    'reg_alpha': 0.5,        # Au lieu de 0.1
    'reg_lambda': 2.0,       # Au lieu de 1.0
    'max_depth': 4           # Au lieu de 6
}
```

**Solution 2: DonnÃ©es dÃ©sÃ©quilibrÃ©es**
```python
# Le systÃ¨me calcule automatiquement scale_pos_weight
# Mais vous pouvez ajuster manuellement:
scale_pos_weight = (nb_non_fraud / nb_fraud) * 1.5  # PÃ©naliser plus les erreurs
```

### ProblÃ¨me: F1 Score trop faible

**Solution: Analyser les features**
```python
import joblib

model = joblib.load('data/automl_models/dataset/xgboost_model.joblib')
importances = model.feature_importances_

# Afficher top 10 features
import pandas as pd
feature_importance = pd.DataFrame({
    'feature': feature_names,
    'importance': importances
}).sort_values('importance', ascending=False)

print(feature_importance.head(10))
```

## ğŸ¤ Contribution

Les contributions sont les bienvenues! Domaines d'amÃ©lioration:
- ğŸ”„ RÃ©entraÃ®ner Meta-Transformer avec plus de datasets
- ğŸ“Š Ajouter d'autres algorithmes (LightGBM, CatBoost)
- ğŸ¯ Optimiser la feature selection
- ğŸ“ˆ Ajouter ensembles methods (stacking)

## ğŸ“„ Licence

Projet Ã©ducatif - Libre d'utilisation

## ğŸ“ Support

Consultez la documentation:
- [Guide d'Utilisation Complet](docs/GUIDE_UTILISATION_AUTOML.md)
- [RÃ©sultats et Analyses](AUTOML_FINAL_RESULTS.md)
- [Troubleshooting](docs/GUIDE_UTILISATION_AUTOML.md#troubleshooting)

---

**CrÃ©Ã© avec â¤ï¸ pour automatiser la dÃ©tection de fraude**  
**Version**: 1.0 | **DerniÃ¨re mise Ã  jour**: 2025-10-18

Projet de dÃ©tection de fraude avec AutoML Meta-Transformer

## ğŸ“ Structure du Projet

```
fraud-project/
â”‚
â”œâ”€â”€ ğŸ“‚ base/                        Scripts de base
â”‚   â”œâ”€â”€ baseline_xgboost.py        EntraÃ®nement XGBoost de base
â”‚   â”œâ”€â”€ extract_structure.py       Extraction de la structure des datasets
â”‚   â”œâ”€â”€ create_metamodel_examples.py  CrÃ©ation des exemples pour meta-learning
â”‚   â”œâ”€â”€ diverse_top5_selector.py   SÃ©lection de configs diverses
â”‚   â”œâ”€â”€ check_fraud_rates.py       Analyse des taux de fraude
â”‚   â””â”€â”€ production_feature_importance_*.py  Importance des features
â”‚
â”œâ”€â”€ ğŸ“‚ automl_transformer/          SystÃ¨me AutoML avec Meta-Transformer
â”‚   â”œâ”€â”€ train_automl_metatransformer.py  EntraÃ®nement du Meta-Transformer
â”‚   â”œâ”€â”€ full_automl.py             Pipeline AutoML complet
â”‚   â”œâ”€â”€ test_learned_metatransformer.py  Tests du modÃ¨le
â”‚   â”œâ”€â”€ auto_feature_engineer.py   Feature engineering automatique
â”‚   â””â”€â”€ auto_feature_selector.py   SÃ©lection automatique des features
â”‚
â”œâ”€â”€ ğŸ“‚ ancien_meta/                 Ancien Meta-Transformer (archivÃ©)
â”‚   â”œâ”€â”€ train_metatransformer.py   Ancien entraÃ®nement
â”‚   â”œâ”€â”€ predict_xgboost_config.py  Anciennes prÃ©dictions
â”‚   â””â”€â”€ create_unified_metatransformer_dataset.py
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                       Scripts de test et debug
â”‚   â”œâ”€â”€ test_full_automl_learned.py  Test du pipeline complet
â”‚   â”œâ”€â”€ test_pipeline.py           Tests du pipeline
â”‚   â”œâ”€â”€ debug_meta_features.py     Debug des meta-features
â”‚   â””â”€â”€ quick_test_config.py       Tests rapides de config
â”‚
â”œâ”€â”€ ğŸ“‚ utils/                       Utilitaires
â”‚   â”œâ”€â”€ utils.py                   Fonctions utilitaires
â”‚   â”œâ”€â”€ fraud_detection.py         DÃ©tection de fraude
â”‚   â””â”€â”€ apply_model_production.py  Application en production
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                        Documentation
â”‚   â”œâ”€â”€ README_METATRANSFORMER.md  Documentation Meta-Transformer
â”‚   â”œâ”€â”€ SCRIPTS_GUIDE.md           Guide des scripts
â”‚   â”œâ”€â”€ DATASET_EXPANSION_TRACKER.md  Suivi des datasets
â”‚   â”œâ”€â”€ DATASET8_QUICK_GUIDE.md    Guide Dataset8
â”‚   â”œâ”€â”€ GRID_COMPARISON_DATASET7_VS_DATASET8.md  Comparaisons
â”‚   â””â”€â”€ PROOF_OF_CONCEPT_REPORT.md  Rapport de concept
â”‚
â””â”€â”€ ğŸ“‚ data/                        DonnÃ©es
    â”œâ”€â”€ datasets/                  Datasets CSV
    â”œâ”€â”€ models/                    ModÃ¨les entraÃ®nÃ©s
    â”œâ”€â”€ structure/                 Structures extraites
    â”œâ”€â”€ Feature_importance/        Importance des features
    â””â”€â”€ metatransformer_training/  DonnÃ©es d'entraÃ®nement Meta-Transformer
```

## ğŸš€ Quick Start

### 1. EntraÃ®nement de base (baseline)
```bash
cd base
python baseline_xgboost.py
```

### 2. Utiliser l'AutoML complet
```python
from automl_transformer.full_automl import FullAutoML

# Avec Meta-Transformer (apprentissage automatique)
automl = FullAutoML(use_meta_transformer=True)
automl.fit('data/datasets/Dataset5.csv', target_col='is_fraud')

# Sans Meta-Transformer (rÃ¨gles basÃ©es sur la structure)
automl = FullAutoML(use_meta_transformer=False)
automl.fit('data/datasets/Dataset9.csv', target_col='fraud_flag')
```

### 3. EntraÃ®ner le Meta-Transformer
```bash
cd automl_transformer
python train_automl_metatransformer.py
```

## ğŸ“Š RÃ©sultats

### Comparaison des approches

| Dataset | Baseline | AutoML (rule-based) | AutoML (Meta-Transformer) |
|---------|----------|---------------------|---------------------------|
| Dataset5 | - | F1=0.3671, ROC=0.8882 | F1=0.3627, ROC=0.8812 |
| Dataset9 | - | F1=0.2121, ROC=0.7116 | F1=0.1792, ROC=0.7147 |

**Conclusion actuelle** : Le mode rule-based est plus fiable. Le Meta-Transformer nÃ©cessite plus de donnÃ©es d'entraÃ®nement (Dataset8, Dataset9) pour mieux gÃ©nÃ©raliser.

## ğŸ”§ DÃ©veloppement

### Ajouter un nouveau dataset
1. Placer le CSV dans `data/datasets/`
2. Extraire la structure : `python base/extract_structure.py Dataset_X.csv`
3. CrÃ©er les exemples : `python base/create_metamodel_examples.py`
4. RÃ©entraÃ®ner : `python automl_transformer/train_automl_metatransformer.py`

### Debug
```bash
cd tests
python debug_meta_features.py  # VÃ©rifier les features extraites
python test_full_automl_learned.py  # Tester le pipeline complet
```

## ğŸ“ Notes

- **Meta-Transformer actuel** : EntraÃ®nÃ© sur Dataset1-7 (105 exemples)
- **Architecture** : Transformer 6 layers, 8 heads, 256 dim
- **EntrÃ©es** : 18 features structure + 20 features importance
- **Sorties** : 10 hyperparams + 20 feature scores + 5 engineering flags

## ğŸ› ProblÃ¨mes connus

1. **Meta-Transformer gÃ©nÃ©ralise mal** sur nouveaux datasets (Dataset8, Dataset9)
   - Solution : Ajouter plus de datasets d'entraÃ®nement
   - Alternative : Utiliser `use_meta_transformer=False` (plus fiable actuellement)

2. **Bug corrigÃ©** : Les meta_features n'Ã©taient pas lues correctement du JSON
   - Fixed dans `full_automl.py` ligne 145-165

## ï¿½ Organisation du Projet

### Structure Principale

```
fraud-project/
â”œâ”€â”€ ğŸ“Š automl_transformer/          AutoML avec Meta-Transformer
â”‚   â”œâ”€â”€ full_automl.py             Point d'entrÃ©e principal
â”‚   â”œâ”€â”€ apply_automl_production.py Script de production
â”‚   â”œâ”€â”€ train_automl_metatransformer.py
â”‚   â”œâ”€â”€ auto_feature_engineer.py   Fallback feature engineering
â”‚   â””â”€â”€ auto_feature_selector.py   Fallback feature selection
â”œâ”€â”€ ğŸ”§ utils/                       Utilitaires partagÃ©s
â”‚   â”œâ”€â”€ column_matcher.py          Matching sÃ©mantique de colonnes
â”‚   â”œâ”€â”€ fraud_detection.py         DÃ©tection de patterns de fraude
â”‚   â””â”€â”€ utils.py                   Fonctions communes
â”œâ”€â”€ ğŸ“ scripts/                     Scripts utilitaires organisÃ©s
â”‚   â”œâ”€â”€ data_generation/           GÃ©nÃ©ration de datasets
â”‚   â”‚   â”œâ”€â”€ generate_realistic_fraud_dataset.py
â”‚   â”‚   â”œâ”€â”€ dataset_configs.py
â”‚   â”‚   â””â”€â”€ generate_model_metadata.py
â”‚   â”œâ”€â”€ retraining/                RÃ©entraÃ®nement de modÃ¨les
â”‚   â”‚   â””â”€â”€ retrain_all_models.py
â”‚   â”œâ”€â”€ debugging/                 Scripts de diagnostic
â”‚   â””â”€â”€ comparison/                Scripts de tests
â”œâ”€â”€ ğŸ—„ï¸ data/                        DonnÃ©es et modÃ¨les
â”‚   â”œâ”€â”€ datasets/                  40 datasets de fraude (Dataset1-40.csv)
â”‚   â”œâ”€â”€ automl_models/             ModÃ¨les entraÃ®nÃ©s (40 dossiers)
â”‚   â”œâ”€â”€ structure/                 MÃ©tadonnÃ©es de structure
â”‚   â””â”€â”€ Feature_importance/        Importance des features
â”œâ”€â”€ ğŸ“œ ancien_meta/                 Anciens scripts Meta-Transformer
â”‚   â”œâ”€â”€ train_metatransformer.py   (version obsolÃ¨te)
â”‚   â””â”€â”€ predict_xgboost_config.py  (version obsolÃ¨te)
â”œâ”€â”€ ğŸš€ apply_automl_production.py   Script de production principal
â””â”€â”€ ğŸ“š docs/                        Documentation technique
```

### Scripts de Production

**Principal:**
- `automl_transformer/apply_automl_production.py` - Pipeline de production complet (seuil optimisÃ© Ã  0.20)
- `automl_transformer/full_automl.py` - AutoML complet avec Meta-Transformer

**GÃ©nÃ©ration de donnÃ©es:**
- `scripts/data_generation/generate_realistic_fraud_dataset.py` - GÃ©nÃ¨re les 40 datasets
- `scripts/data_generation/dataset_configs.py` - Configuration des scÃ©narios de fraude

**Maintenance:**
- `scripts/retraining/retrain_all_models.py` - RÃ©entraÃ®ne tous les modÃ¨les (derniÃ¨re exec: 04/11/2025)

### âš ï¸ Note sur l'Organisation

**Pourquoi auto_feature_engineer/selector sont dans automl_transformer/?**
Ces fichiers ne sont PAS obsolÃ¨tes! Ils sont activement utilisÃ©s comme fallbacks dans `full_automl.py` quand le Meta-Transformer Ã©choue. Les dÃ©placer casserait les imports.

**Vraies archives:** `ancien_meta/` contient les anciens scripts de Meta-Transformer qui ne sont plus utilisÃ©s.

## ï¿½ğŸ“š Documentation complÃ¨te

Voir le dossier `docs/` pour plus de dÃ©tails sur chaque composant.
