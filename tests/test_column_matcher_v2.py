"""
Test de compatibilit√© du module column_matcher.py v2.0
V√©rifie que les autres scripts peuvent l'utiliser sans probl√®me
"""

import sys
sys.path.insert(0, 'C:\\Users\\HP\\Desktop\\fraud-project')

from utils.column_matcher import ColumnMatcher, compare_datasets

def test_basic_usage():
    """Test usage de base (compatibilit√© v1.0)"""
    print("\n" + "="*70)
    print("TEST 1: Usage de base (compatibilit√© v1.0)")
    print("="*70)
    
    matcher = ColumnMatcher(fuzzy_threshold=0.7)
    
    cols1 = ['tx_amount', 'customer_id', 'timestamp']
    cols2 = ['amount', 'client_id', 'tx_time']
    
    result = matcher.calculate_semantic_similarity(cols1, cols2, verbose=False)
    
    print(f"‚úÖ Similarity: {result['similarity']:.1%}")
    print(f"‚úÖ Exact matches: {result['exact_matches']}")
    print(f"‚úÖ Semantic matches: {result['semantic_matches']}")
    print(f"‚úÖ Total matches: {result['total_matches']}")
    
    assert result['similarity'] > 0.7, "Similarity trop basse"
    assert result['total_matches'] >= 2, "Pas assez de matches"
    print("‚úÖ Test 1 PASSED")
    
    return True


def test_new_features():
    """Test nouvelles fonctionnalit√©s v2.0"""
    print("\n" + "="*70)
    print("TEST 2: Nouvelles fonctionnalit√©s v2.0")
    print("="*70)
    
    matcher = ColumnMatcher(fuzzy_threshold=0.7, use_cache=True)
    
    # Test 2.1: Abr√©viations
    print("\n  2.1 - Support abr√©viations")
    cols1 = ['tx_amt', 'cust_id']
    cols2 = ['transaction_amount', 'customer_id']
    result = matcher.calculate_semantic_similarity(cols1, cols2, verbose=False)
    print(f"    ‚úÖ Similarity: {result['similarity']:.1%} (attendu >80%)")
    assert result['similarity'] > 0.8, f"Abr√©viations non match√©es: {result['similarity']}"
    
    # Test 2.2: M√©triques enrichies
    print("\n  2.2 - Nouvelles m√©triques")
    assert 'precision' in result, "M√©trique precision manquante"
    assert 'recall' in result, "M√©trique recall manquante"
    assert 'f1_score' in result, "M√©trique f1_score manquante"
    assert 'confidence' in result, "M√©trique confidence manquante"
    print(f"    ‚úÖ Precision: {result['precision']:.1%}")
    print(f"    ‚úÖ Recall: {result['recall']:.1%}")
    print(f"    ‚úÖ F1-Score: {result['f1_score']:.1%}")
    print(f"    ‚úÖ Confidence: {result['confidence']:.1%}")
    
    # Test 2.3: Qualit√© du match
    print("\n  2.3 - √âvaluation qualit√©")
    quality = matcher.get_match_quality(cols1, cols2)
    print(f"    ‚úÖ Match quality: {quality}")
    assert quality in ['excellent', 'good', 'fair', 'poor', 'incompatible'], "Qualit√© invalide"
    
    # Test 2.4: Suggestions de mapping
    print("\n  2.4 - Suggestions de mapping")
    suggestions = matcher.suggest_column_mapping(['montant'], ['amount', 'value'], top_n=2)
    print(f"    ‚úÖ Suggestions pour 'montant': {list(suggestions['montant'])}")
    assert 'montant' in suggestions, "Suggestions manquantes"
    
    # Test 2.5: Analyse de groupes
    print("\n  2.5 - Analyse de groupes")
    groups = matcher.analyze_column_groups(['tx_id', 'tx_amount', 'customer_id'], verbose=False)
    print(f"    ‚úÖ Groupes d√©tect√©s: {list(groups.keys())}")
    assert 'transaction_id' in groups, "Groupe transaction_id manquant"
    assert 'amount' in groups, "Groupe amount manquant"
    
    print("\n‚úÖ Test 2 PASSED")
    return True


def test_backward_compatibility():
    """Test compatibilit√© avec code existant"""
    print("\n" + "="*70)
    print("TEST 3: Compatibilit√© backward (apply_automl_production.py)")
    print("="*70)
    
    # Simuler usage dans apply_automl_production.py
    matcher = ColumnMatcher(fuzzy_threshold=0.7)
    
    # Pattern utilis√© dans apply_automl_production.py ligne 250
    cols1 = ['amount', 'customer_id', 'timestamp', 'merchant', 'country']
    cols2 = ['tx_amount', 'cust_id', 'tx_time', 'vendor', 'pays']
    
    semantic_result = matcher.calculate_semantic_similarity(cols1, cols2, verbose=False)
    
    # V√©rifier que les cl√©s attendues existent
    required_keys = ['similarity', 'overlap_ratio', 'exact_matches', 'semantic_matches', 
                     'fuzzy_matches', 'total_matches', 'details']
    
    for key in required_keys:
        assert key in semantic_result, f"Cl√© {key} manquante (requis par apply_automl_production.py)"
        print(f"  ‚úÖ {key}: pr√©sent")
    
    print(f"\n‚úÖ Similarity: {semantic_result['similarity']:.1%}")
    print(f"‚úÖ Total matches: {semantic_result['total_matches']}/{len(cols1)}")
    
    print("\n‚úÖ Test 3 PASSED - apply_automl_production.py compatible")
    return True


def test_compare_datasets_function():
    """Test fonction compare_datasets"""
    print("\n" + "="*70)
    print("TEST 4: Fonction compare_datasets")
    print("="*70)
    
    cols1 = ['amount', 'time', 'customer']
    cols2 = ['tx_amt', 'timestamp', 'client_id']
    
    # Test avec use_cache param√®tre (nouveau en v2.0)
    result = compare_datasets(cols1, cols2, fuzzy_threshold=0.7, verbose=False, use_cache=True)
    
    print(f"‚úÖ Similarity: {result['similarity']:.1%}")
    print(f"‚úÖ Match quality: {result['match_quality']}")
    
    assert 'match_quality' in result, "match_quality manquant"
    assert result['similarity'] > 0.5, "Similarity trop basse"
    
    print("\n‚úÖ Test 4 PASSED")
    return True


def test_performance_cache():
    """Test performance avec cache"""
    print("\n" + "="*70)
    print("TEST 5: Performance avec cache")
    print("="*70)
    
    import time
    
    cols1 = ['tx_amount'] * 10 + ['customer_id'] * 10
    cols2 = ['amount'] * 10 + ['client_id'] * 10
    
    # Avec cache
    matcher_cache = ColumnMatcher(fuzzy_threshold=0.7, use_cache=True)
    start = time.time()
    for _ in range(5):
        matcher_cache.calculate_semantic_similarity(cols1, cols2, verbose=False)
    time_with_cache = time.time() - start
    
    # Sans cache
    matcher_no_cache = ColumnMatcher(fuzzy_threshold=0.7, use_cache=False)
    start = time.time()
    for _ in range(5):
        matcher_no_cache.calculate_semantic_similarity(cols1, cols2, verbose=False)
    time_without_cache = time.time() - start
    
    print(f"  Avec cache:    {time_with_cache:.4f}s")
    print(f"  Sans cache:    {time_without_cache:.4f}s")
    print(f"  Speedup:       {time_without_cache/time_with_cache:.2f}x")
    
    print("\n‚úÖ Test 5 PASSED")
    return True


def main():
    """Ex√©cution de tous les tests"""
    print("\n" + "="*70)
    print("üß™ TESTS DE COMPATIBILIT√â - column_matcher.py v2.0")
    print("="*70)
    
    tests = [
        ("Usage de base (v1.0 compatible)", test_basic_usage),
        ("Nouvelles fonctionnalit√©s v2.0", test_new_features),
        ("Compatibilit√© backward", test_backward_compatibility),
        ("Fonction compare_datasets", test_compare_datasets_function),
        ("Performance cache", test_performance_cache)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            success = test_func()
            results.append((test_name, "‚úÖ PASSED"))
        except Exception as e:
            results.append((test_name, f"‚ùå FAILED: {str(e)}"))
            print(f"\n‚ùå FAILED: {str(e)}")
    
    # R√©sum√©
    print("\n" + "="*70)
    print("üìä R√âSUM√â DES TESTS")
    print("="*70)
    
    for test_name, result in results:
        print(f"  {result:15s} - {test_name}")
    
    passed = sum(1 for _, r in results if "PASSED" in r)
    total = len(results)
    
    print(f"\n{'='*70}")
    print(f"R√©sultat: {passed}/{total} tests pass√©s")
    
    if passed == total:
        print("‚úÖ TOUS LES TESTS PASS√âS - column_matcher.py v2.0 est compatible!")
    else:
        print("‚ö†Ô∏è Certains tests ont √©chou√©")
    
    print("="*70)
    
    return passed == total


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
