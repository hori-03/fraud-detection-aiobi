"""
test_apply_automl_production_v2.py

Script de test pour valider toutes les fonctionnalit√©s v2.0
de apply_automl_production.py

Tests:
1. ‚úÖ Exclusion automatique ID/timestamp
2. ‚úÖ Auto-match avec matching s√©mantique
3. ‚úÖ Ensemble predictions (top-3)
4. ‚úÖ Anomaly detection
5. ‚úÖ Calibration des probabilit√©s
6. ‚úÖ Export enrichi (Excel + JSON)
"""

import subprocess
import sys
from pathlib import Path
import pandas as pd
import json

def run_command(cmd, description):
    """Ex√©cute une commande et affiche le r√©sultat"""
    print(f"\n{'='*80}")
    print(f"üß™ TEST: {description}")
    print(f"{'='*80}")
    print(f"üìù Commande: {cmd}")
    print()
    
    result = subprocess.run(cmd, shell=True, capture_output=False, text=True)
    
    if result.returncode == 0:
        print(f"\n‚úÖ TEST R√âUSSI: {description}")
    else:
        print(f"\n‚ùå TEST √âCHOU√â: {description}")
        print(f"   Return code: {result.returncode}")
    
    return result.returncode == 0


def main():
    print(f"\n{'#'*80}")
    print(f"# TEST SUITE - apply_automl_production.py v2.0")
    print(f"{'#'*80}\n")
    
    # V√©rifier que le script existe
    if not Path("apply_automl_production.py").exists():
        print("‚ùå apply_automl_production.py introuvable!")
        sys.exit(1)
    
    # V√©rifier qu'il y a des datasets de test
    test_datasets = list(Path("data/datasets").glob("Dataset3*.csv"))
    if not test_datasets:
        print("‚ùå Aucun dataset de test trouv√© dans data/datasets/")
        sys.exit(1)
    
    test_dataset = str(test_datasets[0])  # Utiliser Dataset30 ou similaire
    print(f"üìä Dataset de test: {test_dataset}")
    
    results = {}
    
    # ============================================================
    # TEST 1: Lister les mod√®les disponibles
    # ============================================================
    success = run_command(
        "python apply_automl_production.py --list_models",
        "Liste des mod√®les disponibles"
    )
    results['test_1_list_models'] = success
    
    # ============================================================
    # TEST 2: Auto-match classique
    # ============================================================
    success = run_command(
        f"python apply_automl_production.py --dataset {test_dataset} --auto_match --output test_output/test2_automatch",
        "Auto-match classique (single model)"
    )
    results['test_2_automatch'] = success
    
    if success:
        # V√©rifier que le fichier CSV existe
        output_file = Path("test_output/test2_automatch.csv")
        if output_file.exists():
            df = pd.read_csv(output_file)
            print(f"\n   ‚úÖ Output CSV cr√©√©: {len(df)} lignes, {len(df.columns)} colonnes")
            print(f"   üìã Colonnes: {list(df.columns)}")
            
            # V√©rifier colonnes attendues
            expected_cols = ['fraud_probability', 'fraud_prediction', 'risk_level']
            missing = [col for col in expected_cols if col not in df.columns]
            if missing:
                print(f"   ‚ö†Ô∏è  Colonnes manquantes: {missing}")
            else:
                print(f"   ‚úÖ Toutes les colonnes attendues pr√©sentes")
        else:
            print(f"   ‚ùå Output CSV non cr√©√©: {output_file}")
            results['test_2_automatch'] = False
    
    # ============================================================
    # TEST 3: Ensemble predictions (top-3)
    # ============================================================
    success = run_command(
        f"python apply_automl_production.py --dataset {test_dataset} --ensemble --top_k 3 --output test_output/test3_ensemble",
        "Ensemble predictions (top-3 models)"
    )
    results['test_3_ensemble'] = success
    
    if success:
        output_file = Path("test_output/test3_ensemble.csv")
        if output_file.exists():
            df = pd.read_csv(output_file)
            print(f"\n   ‚úÖ Output CSV cr√©√©: {len(df)} lignes")
            
            # V√©rifier colonnes sp√©cifiques √† l'ensemble
            ensemble_cols = ['prediction_variance', 'prediction_stability']
            missing = [col for col in ensemble_cols if col not in df.columns]
            if missing:
                print(f"   ‚ö†Ô∏è  Colonnes ensemble manquantes: {missing}")
            else:
                print(f"   ‚úÖ Colonnes ensemble pr√©sentes")
                print(f"      - Stabilit√© moyenne: {df['prediction_stability'].mean():.2%}")
                print(f"      - Variance moyenne: {df['prediction_variance'].mean():.4f}")
    
    # ============================================================
    # TEST 4: Anomaly detection
    # ============================================================
    success = run_command(
        f"python apply_automl_production.py --dataset {test_dataset} --auto_match --anomaly_detection --output test_output/test4_anomaly",
        "Anomaly detection (Isolation Forest)"
    )
    results['test_4_anomaly'] = success
    
    if success:
        output_file = Path("test_output/test4_anomaly.csv")
        if output_file.exists():
            df = pd.read_csv(output_file)
            print(f"\n   ‚úÖ Output CSV cr√©√©")
            
            # V√©rifier colonnes anomaly
            anomaly_cols = ['anomaly_score', 'is_anomaly', 'combined_score']
            missing = [col for col in anomaly_cols if col not in df.columns]
            if missing:
                print(f"   ‚ö†Ô∏è  Colonnes anomaly manquantes: {missing}")
            else:
                print(f"   ‚úÖ Colonnes anomaly pr√©sentes")
                n_anomalies = df['is_anomaly'].sum()
                print(f"      - Anomalies d√©tect√©es: {n_anomalies} ({n_anomalies/len(df):.2%})")
                print(f"      - Score anomaly moyen: {df['anomaly_score'].mean():.3f}")
    
    # ============================================================
    # TEST 5: Calibration
    # ============================================================
    success = run_command(
        f"python apply_automl_production.py --dataset {test_dataset} --auto_match --calibrate --output test_output/test5_calibrate",
        "Calibration des probabilit√©s"
    )
    results['test_5_calibrate'] = success
    
    if success:
        output_file = Path("test_output/test5_calibrate.csv")
        if output_file.exists():
            df = pd.read_csv(output_file)
            print(f"\n   ‚úÖ Output CSV cr√©√©")
            
            if 'fraud_probability_calibrated' in df.columns:
                print(f"   ‚úÖ Colonne fraud_probability_calibrated pr√©sente")
                print(f"      - Proba brute: mean={df['fraud_probability'].mean():.3f}, std={df['fraud_probability'].std():.3f}")
                print(f"      - Proba calibr√©e: mean={df['fraud_probability_calibrated'].mean():.3f}, std={df['fraud_probability_calibrated'].std():.3f}")
            else:
                print(f"   ‚ö†Ô∏è  Colonne fraud_probability_calibrated manquante")
    
    # ============================================================
    # TEST 6: Export enrichi (Excel + JSON)
    # ============================================================
    success = run_command(
        f"python apply_automl_production.py --dataset {test_dataset} --auto_match --rich_export --output test_output/test6_rich",
        "Export enrichi (Excel + JSON)"
    )
    results['test_6_rich_export'] = success
    
    if success:
        # V√©rifier Excel
        excel_file = Path("test_output/test6_rich.xlsx")
        if excel_file.exists():
            print(f"\n   ‚úÖ Fichier Excel cr√©√©: {excel_file}")
            
            # Charger et v√©rifier les sheets
            try:
                xls = pd.ExcelFile(excel_file)
                sheets = xls.sheet_names
                print(f"      Sheets: {sheets}")
                
                expected_sheets = ['All Predictions', 'High Risk', 'Summary']
                missing_sheets = [s for s in expected_sheets if s not in sheets]
                if missing_sheets:
                    print(f"   ‚ö†Ô∏è  Sheets manquants: {missing_sheets}")
                else:
                    print(f"   ‚úÖ Tous les sheets pr√©sents")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Erreur lecture Excel: {e}")
        else:
            print(f"   ‚ùå Fichier Excel non cr√©√©")
            results['test_6_rich_export'] = False
        
        # V√©rifier JSON
        json_file = Path("test_output/test6_rich.json")
        if json_file.exists():
            print(f"\n   ‚úÖ Fichier JSON cr√©√©: {json_file}")
            
            # Charger et v√©rifier structure
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                expected_keys = ['metadata', 'summary_statistics', 'top_10_frauds', 'predictions']
                missing_keys = [k for k in expected_keys if k not in data]
                if missing_keys:
                    print(f"   ‚ö†Ô∏è  Cl√©s manquantes: {missing_keys}")
                else:
                    print(f"   ‚úÖ Toutes les cl√©s pr√©sentes")
                    print(f"      - Total transactions: {data['metadata']['n_total']}")
                    print(f"      - Fraudes d√©tect√©es: {data['metadata']['n_fraud']}")
                    print(f"      - Top 10 frauds: {len(data['top_10_frauds'])} entr√©es")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Erreur lecture JSON: {e}")
        else:
            print(f"   ‚ùå Fichier JSON non cr√©√©")
            results['test_6_rich_export'] = False
    
    # ============================================================
    # TEST 7: Mode batch (si dataset assez gros)
    # ============================================================
    # Skip si dataset < 10k lignes
    try:
        df_test = pd.read_csv(test_dataset)
        if len(df_test) >= 10000:
            success = run_command(
                f"python apply_automl_production.py --dataset {test_dataset} --auto_match --batch_size 5000 --output test_output/test7_batch",
                "Mode batch (5000 lignes/batch)"
            )
            results['test_7_batch'] = success
        else:
            print(f"\n‚è≠Ô∏è  TEST 7 SKIPPED: Dataset trop petit pour batch mode ({len(df_test)} < 10000)")
            results['test_7_batch'] = None
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Erreur lecture dataset: {e}")
        results['test_7_batch'] = None
    
    # ============================================================
    # TEST 8: Ensemble + Anomaly + Calibration (combo complet)
    # ============================================================
    success = run_command(
        f"python apply_automl_production.py --dataset {test_dataset} --ensemble --top_k 2 --anomaly_detection --calibrate --output test_output/test8_full",
        "Combo complet (Ensemble + Anomaly + Calibration)"
    )
    results['test_8_full_combo'] = success
    
    if success:
        output_file = Path("test_output/test8_full.csv")
        if output_file.exists():
            df = pd.read_csv(output_file)
            print(f"\n   ‚úÖ Output CSV cr√©√©: {len(df)} lignes")
            
            # V√©rifier toutes les colonnes avanc√©es
            advanced_cols = [
                'prediction_variance', 'prediction_stability',
                'anomaly_score', 'is_anomaly', 'combined_score',
                'fraud_probability_calibrated'
            ]
            present = [col for col in advanced_cols if col in df.columns]
            missing = [col for col in advanced_cols if col not in df.columns]
            
            print(f"   ‚úÖ Colonnes pr√©sentes ({len(present)}/{len(advanced_cols)}): {present}")
            if missing:
                print(f"   ‚ö†Ô∏è  Colonnes manquantes: {missing}")
    
    # ============================================================
    # R√âSUM√â FINAL
    # ============================================================
    print(f"\n\n{'#'*80}")
    print(f"# R√âSUM√â DES TESTS")
    print(f"{'#'*80}\n")
    
    total = len([v for v in results.values() if v is not None])
    passed = len([v for v in results.values() if v is True])
    failed = len([v for v in results.values() if v is False])
    skipped = len([v for v in results.values() if v is None])
    
    print(f"üìä R√©sultats:")
    print(f"   Total tests: {total}")
    print(f"   ‚úÖ R√©ussis: {passed}")
    print(f"   ‚ùå √âchou√©s: {failed}")
    print(f"   ‚è≠Ô∏è  Skipped: {skipped}")
    print(f"   Taux de r√©ussite: {passed/total*100:.1f}%")
    
    print(f"\nüìã D√©tails:")
    for test_name, result in results.items():
        if result is True:
            status = "‚úÖ PASS"
        elif result is False:
            status = "‚ùå FAIL"
        else:
            status = "‚è≠Ô∏è  SKIP"
        print(f"   {status} - {test_name}")
    
    # V√©rifier fichiers g√©n√©r√©s
    output_dir = Path("test_output")
    if output_dir.exists():
        files = list(output_dir.glob("*"))
        print(f"\nüìÅ Fichiers g√©n√©r√©s ({len(files)}):")
        for f in sorted(files):
            size = f.stat().st_size / 1024  # KB
            print(f"   - {f.name:40s} ({size:8.1f} KB)")
    
    print(f"\n{'#'*80}\n")
    
    # Return code
    if failed > 0:
        print(f"‚ùå {failed} test(s) √©chou√©(s)")
        sys.exit(1)
    else:
        print(f"‚úÖ Tous les tests r√©ussis!")
        sys.exit(0)


if __name__ == "__main__":
    main()
