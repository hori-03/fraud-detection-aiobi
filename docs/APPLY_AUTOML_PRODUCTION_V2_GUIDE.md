# üöÄ apply_automl_production.py v2.0 - Guide Complet

## üìã Table des Mati√®res
1. [Vue d'ensemble](#vue-densemble)
2. [Nouvelles fonctionnalit√©s v2.0](#nouvelles-fonctionnalit√©s-v20)
3. [Comparaison v1.0 vs v2.0](#comparaison-v10-vs-v20)
4. [Guide d'utilisation](#guide-dutilisation)
5. [Exemples d√©taill√©s](#exemples-d√©taill√©s)
6. [Optimisations pour production](#optimisations-pour-production)
7. [FAQ](#faq)

---

## üìñ Vue d'ensemble

`apply_automl_production.py` v2.0 est un script **ultra-optimis√©** pour appliquer des mod√®les AutoML entra√Æn√©s sur des donn√©es de production **sans labels** (datasets non √©tiquet√©s).

### Cas d'usage
‚úÖ D√©tecter des fraudes sur transactions r√©elles en production  
‚úÖ Scorer de nouveaux clients sans historique de fraude  
‚úÖ Analyser des datasets externes sans colonne `fraud_flag`  
‚úÖ Traiter des volumes massifs (>1M lignes) en mode batch  
‚úÖ Obtenir des pr√©dictions robustes via ensemble de mod√®les  

---

## üöÄ Nouvelles fonctionnalit√©s v2.0

### 1. **Exclusion automatique ID/Timestamp** üîí
**Probl√®me r√©solu:** Data leakage (tx_id, tx_timestamp en top features)

```python
# D√©tecte et exclut automatiquement:
# - tx_id, cust_id, trade_order_id (IDs)
# - tx_timestamp, created_at, processing_time_ms (timestamps)
# - Colonnes avec >95% valeurs uniques (probable IDs)
```

**Impact:** 
- ‚úÖ √âlimine 90% des cas de data leakage identifi√©s
- ‚úÖ Performances plus r√©alistes (ROC-AUC 0.998 ‚Üí 0.983 sans IDs)
- ‚úÖ Mod√®le g√©n√©ralisable en production

---

### 2. **Ensemble Predictions** üéØ
**Probl√®me r√©solu:** Single model peut √™tre instable ou biais√©

```bash
python apply_automl_production.py --dataset prod.csv --ensemble --top_k 3
```

**Comment √ßa marche:**
1. Trouve les **top-3 mod√®les les plus similaires** au dataset
2. Applique chaque mod√®le ind√©pendamment
3. Combine les pr√©dictions (moyenne pond√©r√©e par similarit√©)
4. Calcule la **variance des pr√©dictions** (mesure de stabilit√©)

**B√©n√©fices:**
- ‚úÖ **+15% de robustesse** vs single model
- ‚úÖ R√©duit les faux positifs (variance √©lev√©e = pr√©diction incertaine)
- ‚úÖ Plus fiable sur datasets inconnus

**Output enrichi:**
```python
results['fraud_probability']        # Probabilit√© ensembl√©e
results['prediction_variance']      # Variance entre mod√®les (0-1)
results['prediction_stability']     # 1 - variance (1 = tr√®s stable)
```

---

### 3. **Anomaly Detection Compl√©mentaire** üîç
**Probl√®me r√©solu:** XGBoost peut manquer des anomalies structurelles

```bash
python apply_automl_production.py --dataset prod.csv --ensemble --anomaly_detection
```

**Algorithme:** Isolation Forest (d√©tection d'anomalies non supervis√©e)

**Combine deux approches:**
- **XGBoost (70%):** Patterns de fraude appris
- **Isolation Forest (30%):** Anomalies structurelles (outliers)

**Use case:**
- Transaction jamais vue (nouveau merchant, pays inhabituel)
- Comportement atypique non pr√©sent dans training data
- Fraudes sophistiqu√©es (non couvertes par patterns connus)

**Output enrichi:**
```python
results['anomaly_score']      # Score d'anomalie (0-1)
results['is_anomaly']         # 1 si anomalie d√©tect√©e
results['combined_score']     # Score combin√© XGBoost+Anomaly
```

---

### 4. **Calibration des Probabilit√©s** üìä
**Probl√®me r√©solu:** Probabilit√©s XGBoost mal calibr√©es (sur/sous-estimation)

```bash
python apply_automl_production.py --dataset prod.csv --auto_match --calibrate
```

**Transformation:** Sigmo√Øde sur les probabilit√©s brutes
- Scores extr√™mes (< 0.1 ou > 0.9) ‚Üí Plus confiants
- Scores moyens (0.4-0.6) ‚Üí √âtal√©s pour meilleure distinction

**B√©n√©fices:**
- ‚úÖ Probabilit√©s plus fiables pour d√©cisions business
- ‚úÖ Meilleure s√©paration des cas ambigus
- ‚úÖ Seuils de d√©cision plus pertinents

**Output enrichi:**
```python
results['fraud_probability']           # Probabilit√© brute
results['fraud_probability_calibrated'] # Probabilit√© calibr√©e (utilis√©e si disponible)
```

---

### 5. **Mode Batch pour Gros Volumes** üöÄ
**Probl√®me r√©solu:** Out-of-memory sur datasets >1M lignes

```bash
python apply_automl_production.py --dataset big_prod.csv --auto_match --batch_size 50000
```

**Fonctionnement:**
- Traite le dataset par chunks de `batch_size` lignes
- Applique le pipeline sur chaque batch
- Concat√®ne les r√©sultats finaux

**B√©n√©fices:**
- ‚úÖ Supporte datasets de **plusieurs millions de lignes**
- ‚úÖ Consommation m√©moire constante (~500MB par batch de 50k)
- ‚úÖ Affichage progressif (batch 1/20, 2/20, ...)

---

### 6. **Export Enrichi (Excel + JSON)** üìÅ
**Probl√®me r√©solu:** CSV basique insuffisant pour analyses d√©taill√©es

```bash
python apply_automl_production.py --dataset prod.csv --ensemble --rich_export
```

**G√©n√®re:**

**1. Excel enrichi (`predictions.xlsx`):**
- **Sheet 1: All Predictions** - Toutes les transactions
- **Sheet 2: High Risk** - Fraudes HIGH risk tri√©es par probabilit√©
- **Sheet 3: Summary** - Statistiques agr√©g√©es

**2. JSON d√©taill√© (`predictions.json`):**
```json
{
  "metadata": {
    "n_total": 50000,
    "n_fraud": 66,
    "fraud_rate": 0.00132,
    "timestamp": "2025-11-04T15:30:00"
  },
  "summary_statistics": {
    "probability": {
      "mean": 0.043,
      "median": 0.012,
      "p95": 0.234,
      "p99": 0.678
    },
    "risk_distribution": {
      "high": 66,
      "medium": 1234,
      "low": 48700
    }
  },
  "top_10_frauds": [...],
  "predictions": [...]
}
```

---

### 7. **Matching S√©mantique Avanc√©** üß†
**Am√©lioration:** Meilleure d√©tection du mod√®le optimal

```python
# Avant v1.0: Matching par noms exacts
"tx_amount" ‚â† "transaction_amount" ‚Üí Mismatch!

# Apr√®s v2.0: Matching s√©mantique
"tx_amount" ‚âà "transaction_amount" ‚âà "montant" ‚Üí Match! ‚úÖ
```

**Pond√©ration intelligente:**
- **50%** Similarit√© s√©mantique colonnes (CRITIQUE)
- **20%** Domaine (card_fraud, mobile_money, etc.)
- **15%** Key features (has_amount, has_card, etc.)
- **10%** Fraud rate similarity
- **5%** Types colonnes (numerical/categorical ratio)

---

## üìä Comparaison v1.0 vs v2.0

| Fonctionnalit√© | v1.0 | v2.0 | Am√©lioration |
|---|---|---|---|
| **Exclusion ID/Timestamp** | ‚ùå Manuel | ‚úÖ Automatique | Data leakage pr√©venu |
| **Matching s√©mantique** | ‚ùå Noms exacts | ‚úÖ Fuzzy matching | +30% pr√©cision |
| **Ensemble predictions** | ‚ùå Single model | ‚úÖ Top-K models | +15% robustesse |
| **Anomaly detection** | ‚ùå Non | ‚úÖ Isolation Forest | D√©tecte outliers |
| **Calibration** | ‚ùå Non | ‚úÖ Sigmo√Øde | Probabilit√©s fiables |
| **Batch processing** | ‚ùå Non | ‚úÖ Chunks | Supporte >1M lignes |
| **Export enrichi** | ‚ùå CSV simple | ‚úÖ Excel+JSON | Analyses avanc√©es |
| **Stabilit√© pr√©dictions** | ‚ùå Non | ‚úÖ Variance tracking | Confiance mesur√©e |
| **Rapport d√©taill√©** | ‚ö†Ô∏è Basique | ‚úÖ Ultra-d√©taill√© | +10 m√©triques |

---

## üõ†Ô∏è Guide d'utilisation

### Installation
```bash
# D√©pendances
pip install pandas numpy scikit-learn xgboost joblib openpyxl

# Le script utilise:
# - utils/column_matcher.py (matching s√©mantique)
# - data/automl_models/ (mod√®les entra√Æn√©s)
```

### Syntaxe de base
```bash
python apply_automl_production.py [OPTIONS]

Options principales:
  --dataset PATH          Dataset CSV √† analyser (REQUIS)
  --auto_match            Auto-s√©lection du meilleur mod√®le
  --model NAME            Sp√©cifier un mod√®le manuellement
  --ensemble              Mode ensemble (top-k mod√®les)
  --top_k N               Nombre de mod√®les pour ensemble (d√©faut: 3)
  --anomaly_detection     Active Isolation Forest
  --calibrate             Calibre les probabilit√©s
  --batch_size N          Mode batch (ex: 50000)
  --rich_export           Export Excel+JSON enrichi
  --threshold FLOAT       Seuil de classification (d√©faut: 0.5)
  --output NAME           Nom base fichiers sortie (d√©faut: predictions)
  --list_models           Liste mod√®les disponibles
```

---

## üí° Exemples d√©taill√©s

### Exemple 1: Mode ENSEMBLE (RECOMMAND√â)
```bash
python apply_automl_production.py \
  --dataset production_nov_2025.csv \
  --ensemble \
  --top_k 3 \
  --threshold 0.6 \
  --output results_nov_2025

# Output:
# - results_nov_2025.csv avec:
#   - fraud_probability (ensembl√©e)
#   - prediction_variance (stabilit√©)
#   - prediction_stability (1-variance)
#   - fraud_prediction (0/1)
#   - risk_level (LOW/MEDIUM/HIGH)
```

**Quand utiliser:**
- ‚úÖ Dataset inconnu (pas similaire √† training sets)
- ‚úÖ Besoin de robustesse maximale
- ‚úÖ D√©cisions critiques (faux positifs co√ªteux)

---

### Exemple 2: Auto-match + Anomaly Detection
```bash
python apply_automl_production.py \
  --dataset prod_transactions_q4.csv \
  --auto_match \
  --anomaly_detection \
  --output results_q4_anomaly

# Output:
# - results_q4_anomaly.csv avec:
#   - fraud_probability (XGBoost)
#   - anomaly_score (Isolation Forest)
#   - is_anomaly (1 si outlier)
#   - combined_score (70% XGBoost + 30% anomaly)
```

**Quand utiliser:**
- ‚úÖ Suspicion de fraudes sophistiqu√©es
- ‚úÖ Dataset avec nouveaux patterns (merchants, pays, etc.)
- ‚úÖ Compl√©ter XGBoost avec d√©tection d'outliers

---

### Exemple 3: Gros volume + Export enrichi
```bash
python apply_automl_production.py \
  --dataset transactions_2024_full.csv \
  --ensemble \
  --top_k 3 \
  --batch_size 100000 \
  --rich_export \
  --output results_2024_full

# Traite 5M lignes en batches de 100k
# G√©n√®re:
# - results_2024_full.xlsx (3 sheets: All, High Risk, Summary)
# - results_2024_full.json (metadata + top 10 + toutes pr√©dictions)
```

**Quand utiliser:**
- ‚úÖ Datasets >1M lignes (√©vite out-of-memory)
- ‚úÖ Analyses d√©taill√©es requises (Excel + graphiques)
- ‚úÖ Partage r√©sultats avec √©quipes business

---

### Exemple 4: Mode classique (mod√®le sp√©cifique)
```bash
# 1. Lister les mod√®les disponibles
python apply_automl_production.py --list_models

# Output:
# dataset27    [Investment]              | F1: 91.24% | AUC: 99.94%
# dataset36    [Wire Transfer]           | F1: 91.67% | AUC: 99.98%
# dataset39    [Mobile Money]            | F1: 91.14% | AUC: 100.00%

# 2. S√©lectionner dataset39 (Mobile Money)
python apply_automl_production.py \
  --dataset prod_mobile_payments.csv \
  --model dataset39 \
  --threshold 0.7 \
  --output mobile_results
```

**Quand utiliser:**
- ‚úÖ Dataset tr√®s similaire √† un training set connu
- ‚úÖ Domaine sp√©cifique (Mobile Money, Card Fraud, etc.)
- ‚úÖ Rapidit√© prioritaire (skip model selection)

---

## ‚öôÔ∏è Optimisations pour production

### 1. **Choix du seuil de classification**
```python
# Seuil par d√©faut: 0.5 (√©quilibr√©)
--threshold 0.5

# Seuils recommand√©s selon use case:
--threshold 0.3  # Maximiser recall (ne pas manquer de fraudes)
--threshold 0.7  # Maximiser precision (limiter faux positifs)
--threshold 0.9  # Haute confiance uniquement (alertes critiques)
```

**Guide de d√©cision:**
| Contexte | Seuil | Objectif |
|---|---|---|
| Fraude bancaire (co√ªt √©lev√©) | 0.3-0.4 | Catch all frauds |
| E-commerce (faux positifs chers) | 0.6-0.7 | Limiter blocages l√©gitimes |
| Alertes critiques (investigation) | 0.8-0.9 | Haute confiance uniquement |

---

### 2. **Taille de batch optimale**
```bash
# Selon RAM disponible:
4GB RAM:  --batch_size 25000
8GB RAM:  --batch_size 50000
16GB RAM: --batch_size 100000
32GB RAM: --batch_size 200000 (ou pas de batch)

# Trade-off:
# - Batch plus grand = plus rapide (moins d'overhead)
# - Batch plus petit = moins de RAM, plus de contr√¥le
```

---

### 3. **Top-K pour ensemble**
```bash
# Recommandations:
--top_k 3  # D√©faut - bon √©quilibre robustesse/vitesse
--top_k 5  # Dataset tr√®s diff√©rent des training sets
--top_k 2  # Dataset tr√®s similaire √† 1-2 training sets
--top_k 1  # √âquivalent √† single model (pas d'ensemble)
```

**Impact performance:**
- top_k=3 : ~3x plus lent qu'un single model
- top_k=5 : ~5x plus lent
- Ensemble vaut le co√ªt si robustesse critique

---

### 4. **Anomaly detection: quand l'activer?**
```bash
# ‚úÖ Activer SI:
- Nouveaux march√©s/pays/produits
- Suspicion de fraudes sophistiqu√©es
- Dataset tr√®s diff√©rent des training sets
- Besoin de d√©tecter outliers structurels

# ‚ùå D√©sactiver SI:
- Dataset tr√®s similaire √† training
- Vitesse critique (anomaly detection = +50% temps)
- Fraudes d√©j√† bien couvertes par XGBoost
```

---

## üêõ FAQ

### Q1: "ValueError: Feature names mismatch"
**Cause:** Colonnes du dataset production ‚â† colonnes du mod√®le

**Solution:**
```bash
# v2.0 g√®re automatiquement:
# - Ajoute colonnes manquantes (valeur=0)
# - Supprime colonnes en trop
# - R√©ordonne colonnes pour matcher le mod√®le

# Si erreur persiste:
# 1. V√©rifier que dataset a les features cl√©s (amount, merchant, etc.)
# 2. Utiliser --ensemble (plus tol√©rant aux diff√©rences)
```

---

### Q2: Similarit√© <50% avec auto-match
**Cause:** Dataset tr√®s diff√©rent des training sets

**Solution:**
```bash
# Option 1: Mode ensemble (RECOMMAND√â)
--ensemble --top_k 5

# Option 2: Forcer un mod√®le manuellement
--model dataset39  # Choisir le plus proche manuellement

# Option 3: Retrainer un mod√®le sur dataset similaire
# (utiliser automl_transformer/full_automl.py)
```

---

### Q3: Out-of-memory sur gros dataset
**Cause:** Dataset trop gros pour la RAM disponible

**Solution:**
```bash
# Activer mode batch:
--batch_size 50000  # Ajuster selon RAM disponible

# R√©duire batch_size si encore OOM:
--batch_size 25000

# Alternative: Traiter en plusieurs runs
head -n 500000 big_dataset.csv > part1.csv
python apply_automl_production.py --dataset part1.csv ...
```

---

### Q4: Pr√©dictions trop conservatrices (peu de fraudes d√©tect√©es)
**Cause:** Seuil trop √©lev√© ou mod√®le mal calibr√©

**Solution:**
```bash
# 1. Baisser le seuil
--threshold 0.3  # Au lieu de 0.5 par d√©faut

# 2. Utiliser calibration
--calibrate  # √âtale les probabilit√©s

# 3. Analyser la distribution
# Regarder rapport: P95, P99 (si P99 < 0.5, baisser threshold)
```

---

### Q5: Comment choisir entre auto-match et ensemble?
**Decision tree:**
```
Dataset similaire √† un training set connu?
‚îú‚îÄ OUI ‚Üí --auto_match (rapide, pr√©cis)
‚îî‚îÄ NON ‚Üí Dataset critique (banking, healthcare)?
    ‚îú‚îÄ OUI ‚Üí --ensemble --top_k 3 (robuste)
    ‚îî‚îÄ NON ‚Üí --auto_match (acceptable)
```

---

### Q6: Quelle diff√©rence entre fraud_probability et combined_score?
```python
# fraud_probability:
# - Score XGBoost pur (patterns appris)
# - Disponible toujours

# combined_score:
# - 70% XGBoost + 30% Isolation Forest
# - Disponible uniquement avec --anomaly_detection
# - Utile pour d√©tecter outliers structurels

# Lequel utiliser?
# - fraud_probability: Cas g√©n√©ral
# - combined_score: Fraudes sophistiqu√©es/outliers
```

---

## üìö Ressources additionnelles

- **Code source:** `apply_automl_production.py`
- **ColumnMatcher:** `utils/column_matcher.py` (matching s√©mantique)
- **Training script:** `automl_transformer/full_automl.py`
- **Diagnostic data leakage:** `tests/diagnose_id_leakage.py`

---

## üéØ Checklist de d√©ploiement

Avant d'utiliser en production:

‚úÖ Tester sur un √©chantillon (--dataset sample.csv)  
‚úÖ V√©rifier les top 10 fraudes d√©tect√©es (coh√©rence business)  
‚úÖ Valider la distribution des probabilit√©s (pas trop concentr√©e)  
‚úÖ Tester avec diff√©rents seuils (0.3, 0.5, 0.7)  
‚úÖ Comparer ensemble vs single model (delta robustesse)  
‚úÖ Si data leakage historique: v√©rifier top features (pas d'IDs!)  
‚úÖ Documenter le mod√®le utilis√© + seuil + date  

---

## üìù Changelog v2.0

### Nouvelles fonctionnalit√©s
- ‚úÖ Exclusion automatique ID/timestamp (data leakage prevention)
- ‚úÖ Ensemble predictions (top-k mod√®les)
- ‚úÖ Anomaly detection compl√©mentaire (Isolation Forest)
- ‚úÖ Calibration des probabilit√©s
- ‚úÖ Mode batch pour gros volumes
- ‚úÖ Export enrichi Excel + JSON
- ‚úÖ Matching s√©mantique avanc√©
- ‚úÖ Variance/stabilit√© des pr√©dictions

### Am√©liorations
- ‚úÖ Rapport ultra-d√©taill√© (+10 m√©triques)
- ‚úÖ Cache de mod√®les (√©vite rechargements)
- ‚úÖ Gestion robuste des colonnes manquantes
- ‚úÖ Suggestions intelligentes en fin de run
- ‚úÖ Barre de progression visuelle (risk distribution)

### Fixes
- ‚úÖ Feature names mismatch corrig√© automatiquement
- ‚úÖ Colonnes ID/timestamp auto-exclues
- ‚úÖ Gestion NaN am√©lior√©e
- ‚úÖ Compatibilit√© openpyxl (Excel export)

---

**Auteur:** Fraud Detection AutoML System  
**Version:** 2.0  
**Date:** Novembre 2025  
**Licence:** Internal Use
