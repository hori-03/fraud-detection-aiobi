# üöÄ GUIDE DE D√âPLOIEMENT EN PRODUCTION

## üî• PROBL√àME: Fichiers Locaux Non Disponibles sur Railway

Railway est **√©ph√©m√®re** : les fichiers disparaissent √† chaque red√©marrage. Vos 40 mod√®les XGBoost (`.joblib`, ~2 GB total) ne seront PAS persistants !

---

## üí° SOLUTION IMPL√âMENT√âE: Architecture Hybride

### üìä PostgreSQL (Railway - Gratuit)
- **Stocke:** M√©tadonn√©es des 40 mod√®les (rapide, <100ms)
- **Table:** `reference_models` avec colonnes compl√®tes
- **Usage:** Auto-matching, statistiques d'utilisation

### ‚òÅÔ∏è AWS S3 (Production - Recommand√©)
- **Stocke:** Fichiers `.joblib` (mod√®les XGBoost)
- **Co√ªt:** ~$0.05-0.10/mois pour 40 mod√®les
- **Avantages:** Persistant, rapide, scalable

### üíæ Cache Local (Railway - Temporaire)
- **Dossier:** `/tmp/model_cache/`
- **Usage:** T√©l√©charge une fois de S3, r√©utilise
- **Expiration:** Nettoy√© au red√©marrage (acceptable)

---

## üèóÔ∏è ARCHITECTURE DE PRODUCTION

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        USER UPLOADS CSV                         ‚îÇ
‚îÇ                     (unlabeled dataset)                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FLASK APP (Railway)                          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  1. Extract columns: ['tx_amount', 'merchant', 'timestamp']    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  2. Query PostgreSQL:                                           ‚îÇ
‚îÇ     ReferenceModel.find_best_match(columns)                     ‚îÇ
‚îÇ     ‚Üí Returns: dataset16 (similarity: 56%)                      ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  3. Load model from S3 (via ModelStorageService):              ‚îÇ
‚îÇ     - Check cache: /tmp/model_cache/dataset16/                 ‚îÇ
‚îÇ     - If not cached: Download from S3                           ‚îÇ
‚îÇ     - Load: xgboost_model.joblib (30 MB)                       ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  4. Apply ensemble predictions:                                 ‚îÇ
‚îÇ     - Top-3 models: dataset16, dataset13, dataset10            ‚îÇ
‚îÇ     - Weighted average predictions                              ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  5. Anomaly detection + Calibration                            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  6. Return predictions CSV                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ                 ‚îÇ                                ‚îÇ
            ‚ñº                 ‚ñº                                ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   PostgreSQL  ‚îÇ  ‚îÇ   AWS S3     ‚îÇ          ‚îÇ   Local Cache    ‚îÇ
    ‚îÇ   (Railway)   ‚îÇ  ‚îÇ              ‚îÇ          ‚îÇ   (/tmp/)        ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§          ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ ‚úì M√©tadonn√©es ‚îÇ  ‚îÇ ‚úì .joblib    ‚îÇ          ‚îÇ ‚úì Temp storage   ‚îÇ
    ‚îÇ ‚úì Fast query  ‚îÇ  ‚îÇ ‚úì Persistent ‚îÇ          ‚îÇ ‚úì Fast access    ‚îÇ
    ‚îÇ ‚úì Statistiques‚îÇ  ‚îÇ ‚úì Scalable   ‚îÇ          ‚îÇ ‚úó Ephemeral      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìù √âTAPES DE D√âPLOIEMENT

### ‚úÖ √âTAPE 1: Pr√©parer AWS S3 (5 minutes)

#### 1.1 Cr√©er un compte AWS (si n√©cessaire)
- Allez sur https://aws.amazon.com/free/
- 12 mois gratuits (5 GB S3 inclus)

#### 1.2 Cr√©er un bucket S3
```bash
# Installer AWS CLI
pip install awscli

# Configurer les credentials
aws configure
# AWS Access Key ID: <votre_access_key>
# AWS Secret Access Key: <votre_secret_key>
# Default region: us-east-1
# Default output format: json

# Cr√©er le bucket
aws s3 mb s3://fraud-detection-models

# V√©rifier
aws s3 ls
```

#### 1.3 Configurer les permissions (IAM)
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:PutObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::fraud-detection-models/*",
        "arn:aws:s3:::fraud-detection-models"
      ]
    }
  ]
}
```

---

### ‚úÖ √âTAPE 2: Migrer les Mod√®les Locaux ‚Üí S3

#### 2.1 Installer boto3
```bash
cd APP_autoML
pip install boto3
```

#### 2.2 Estimer les co√ªts
```bash
python migrate_models_to_s3.py --estimate
```

**Output attendu:**
```
================================================================================
S3 COST ESTIMATION
================================================================================
  Total models: 40
  Total size: 1875.34 MB (1.832 GB)

  Costs (monthly):
    Storage: $0.0421/month
    Upload (one-time): $0.0008
    Yearly storage: $0.51/year

  üí° Tip: Use S3 Intelligent-Tiering for cost optimization
================================================================================
```

#### 2.3 Dry-run (simulation)
```bash
python migrate_models_to_s3.py --bucket fraud-detection-models --dry-run
```

#### 2.4 Migration r√©elle
```bash
python migrate_models_to_s3.py --bucket fraud-detection-models
```

**Output attendu:**
```
Migrating: dataset1
  Local path: data/automl_models/dataset1
  S3 path: s3://fraud-detection-models/automl_models/dataset1/
    Uploading xgboost_model.joblib...
    ‚úì xgboost_model.joblib uploaded
    Uploading feature_engineer.joblib...
    ‚úì feature_engineer.joblib uploaded
    ...
  ‚úÖ Migration successful

...

================================================================================
MIGRATION SUMMARY
================================================================================
  Total models: 40
  ‚úÖ Migrated: 40
  ‚ùå Failed: 0

‚úÖ Migration complete!
```

#### 2.5 V√©rifier la migration
```bash
python migrate_models_to_s3.py --bucket fraud-detection-models --verify
```

---

### ‚úÖ √âTAPE 3: Configurer Railway

#### 3.1 Ajouter les variables d'environnement
Dans Railway Dashboard ‚Üí Variables:

```env
# AWS Credentials
AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
AWS_DEFAULT_REGION=us-east-1

# S3 Bucket
S3_MODEL_BUCKET=fraud-detection-models

# PostgreSQL (auto-configur√© par Railway)
DATABASE_URL=postgresql://...

# Flask
FLASK_ENV=production
SECRET_KEY=<votre_secret_key>
```

#### 3.2 Mettre √† jour requirements.txt
```bash
# Ajouter boto3
echo "boto3==1.34.42" >> requirements.txt
```

#### 3.3 Pousser sur Railway
```bash
git add .
git commit -m "feat: Add S3 storage support for production models"
git push origin main
```

Railway va automatiquement:
1. Rebuild l'image Docker
2. Cr√©er la table `reference_models` (via migrations)
3. Configurer les variables d'environnement

---

### ‚úÖ √âTAPE 4: Peupler la Base de Donn√©es PostgreSQL

#### 4.1 SSH dans Railway (ou run via dashboard)
```bash
# Dans Railway Dashboard ‚Üí Shell
cd /app
python populate_reference_models.py
```

**OU via script local:**
```bash
# Avec DATABASE_URL de Railway
export DATABASE_URL="postgresql://user:pass@host:5432/db"
python populate_reference_models.py
```

**Output attendu:**
```
================================================================================
üì¶ POPULATING REFERENCE MODELS FROM data/automl_models/
================================================================================

Processing dataset1...
  ‚úì Model metadata loaded
  ‚úì Performance metrics loaded
  ‚úì Storage type: s3
  ‚úì S3 path: s3://fraud-detection-models/automl_models/dataset1/
  ‚úÖ Added: dataset1

...

================================================================================
‚úÖ POPULATION COMPLETED
================================================================================
  Total: 40 models added
  Skipped: 0 (already exists)
  Failed: 0
================================================================================
```

---

### ‚úÖ √âTAPE 5: Tester en Production

#### 5.1 Via l'interface web
1. Allez sur https://your-app.railway.app/upload
2. Uploadez un CSV non √©tiquet√©
3. Cochez "Dataset non √©tiquet√©"
4. Cliquez "Appliquer le mod√®le"
5. V√©rifiez les logs:

```
üîç Finding best matching reference models...
‚úÖ Best match: dataset16 (similarity: 56.3%)

üì¶ ModelStorageService: Loading model dataset16 (storage: s3)
  Loading from S3: s3://fraud-detection-models/automl_models/dataset16/
  ‚úì Using cached version: /tmp/model_cache/dataset16
  ‚úì Model loaded

ü§ñ Applying ensemble predictions (top 3 models)...
  Top-3 models: dataset16, dataset13, dataset10
  ‚úÖ Predictions complete (5000 transactions)
```

#### 5.2 Via API (cURL)
```bash
curl -X POST https://your-app.railway.app/api/apply_unlabeled \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "filepath": "uploads/test.csv",
    "model_name": "unlabeled_predictions"
  }'
```

**Response attendu:**
```json
{
  "success": true,
  "message": "Pr√©dictions g√©n√©r√©es avec succ√®s sur 5000 transactions",
  "predictions_file": "uploads/predictions/1_20251104_unlabeled.csv",
  "download_url": "/download/predictions/1_20251104_unlabeled.csv",
  "stats": {
    "total_transactions": 5000,
    "high_risk": 50,
    "medium_risk": 200,
    "low_risk": 4750,
    "anomalies_detected": 25
  },
  "methods_used": {
    "ensemble": true,
    "top_k_models": 3,
    "anomaly_detection": true,
    "calibration": true,
    "best_model": "dataset16",
    "similarity_score": 0.563
  }
}
```

---

## üîß MAINTENANCE

### Ajouter un Nouveau Mod√®le

```bash
# 1. Entra√Æner localement
python full_automl.py --dataset new_data.csv

# 2. Upload vers S3
python migrate_models_to_s3.py --bucket fraud-detection-models

# 3. Ajouter √† PostgreSQL
python populate_reference_models.py
```

### Nettoyer le Cache

```python
from app.services.model_storage import get_storage_service

storage = get_storage_service()
storage.clear_cache()  # Nettoie tout le cache
storage.clear_cache('dataset16')  # Nettoie un mod√®le sp√©cifique
```

### Rollback vers Local (d√©veloppement)

```bash
python migrate_models_to_s3.py --rollback
```

---

## üí∞ CO√õTS ESTIM√âS

### AWS S3 (Storage)
- **40 mod√®les** (~1.8 GB total)
- **$0.023/GB/month** = **$0.04/month**
- **$0.50/year**

### AWS S3 (Data Transfer)
- **GET requests:** $0.0004 per 1,000 requests
- **Estimation:** 1000 pr√©dictions/jour = 3 GET requests/pr√©diction = 90,000 requests/mois
- **Co√ªt:** $0.036/month
- **Avec cache:** Divis√© par 10 = **$0.004/month**

### Railway (Base de Donn√©es PostgreSQL)
- **Gratuit** (jusqu'√† 500 MB)
- Table `reference_models`: ~5 MB
- **$0/month**

### TOTAL ESTIM√â: **$0.05-0.10/month** (~‚Ç¨0.05-0.10)

---

## üö® ALTERNATIVES (Si S3 trop complexe)

### Option B: Railway Volumes
```bash
# Dans Railway Dashboard
# Add Volume: /data (1 GB = $0.25/month)
# Mount √†: /app/data
# Copier mod√®les dans le volume
```

**Avantages:** Simple, int√©gr√© Railway  
**Inconv√©nients:** Co√ªt plus √©lev√© ($3/year vs $0.50/year)

### Option C: Docker Image (Simple mais volumineux)
```dockerfile
# Dans Dockerfile
COPY data/automl_models/ /app/data/automl_models/
```

**Avantages:** Ultra simple, gratuit  
**Inconv√©nients:** Image √©norme (>2 GB), build lent, pas de mise √† jour dynamique

---

## üìä COMPARAISON DES SOLUTIONS

| Solution | Co√ªt/mois | Persistant | Scalable | Complexit√© | Recommandation |
|----------|-----------|------------|----------|------------|----------------|
| **AWS S3** | $0.05 | ‚úÖ | ‚úÖ‚úÖ‚úÖ | Medium | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| Railway Volumes | $0.25 | ‚úÖ | ‚úÖ | Low | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Docker Image | $0 | ‚úÖ | ‚ùå | Very Low | ‚≠ê‚≠ê‚≠ê |
| PostgreSQL BLOB | $0 | ‚úÖ | ‚úÖ | Medium | ‚≠ê‚≠ê |

**Recommandation finale:** **AWS S3** (meilleur rapport qualit√©/prix/scalabilit√©)

---

## ‚úÖ CHECKLIST DE D√âPLOIEMENT

- [ ] Compte AWS cr√©√©
- [ ] Bucket S3 cr√©√© (`fraud-detection-models`)
- [ ] AWS credentials configur√©es
- [ ] boto3 install√© (`pip install boto3`)
- [ ] Co√ªts estim√©s (`python migrate_models_to_s3.py --estimate`)
- [ ] Migration dry-run test√©e
- [ ] Migration vers S3 compl√®te (40 mod√®les)
- [ ] Migration v√©rifi√©e (`--verify`)
- [ ] Variables d'environnement Railway configur√©es
- [ ] `requirements.txt` mis √† jour avec `boto3`
- [ ] Code pouss√© sur Railway
- [ ] Table `reference_models` cr√©√©e (migrations)
- [ ] Table popul√©e avec 40 mod√®les
- [ ] Test avec CSV non √©tiquet√© via web
- [ ] Test avec API endpoint
- [ ] Logs v√©rifi√©s (S3 download + cache)
- [ ] Predictions CSV t√©l√©charg√©es avec succ√®s

---

## üéâ R√âSULTAT FINAL

Votre app est maintenant **production-ready** :

1. ‚úÖ **PostgreSQL** (Railway): M√©tadonn√©es rapides
2. ‚úÖ **AWS S3**: Mod√®les persistants
3. ‚úÖ **Cache local**: Optimisation performance
4. ‚úÖ **Auto-matching**: Top-3 mod√®les similaires
5. ‚úÖ **Ensemble + Anomaly + Calibration**: Pr√©dictions robustes
6. ‚úÖ **Co√ªt**: ~$0.05/mois (~‚Ç¨0.05)

**Les utilisateurs peuvent uploader des CSV non √©tiquet√©s et obtenir des pr√©dictions fiables en quelques secondes !** üöÄ

---

**Document cr√©√©:** 4 novembre 2025  
**Auteur:** Fraud Detection AutoML System v2.0  
**Status:** ‚úÖ PR√äT POUR PRODUCTION
